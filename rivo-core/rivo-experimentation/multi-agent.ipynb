{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST EN TS AVEC LANGGRAPH D'UNE ORCHESTRATION DE MULTI AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, Annotation } from \"npm:@langchain/langgraph\";\n",
    "import { BaseMessage } from \"npm:@langchain/core/messages\";\n",
    "\n",
    "// This defines the object that is passed between each node\n",
    "// in the graph. We will create different nodes for each agent and tool\n",
    "const AgentState = Annotation.Root({\n",
    "    messages: Annotation<BaseMessage[]>({\n",
    "        reducer: (x, y) => x.concat(y),\n",
    "        default: () => [],\n",
    "    }),\n",
    "    // The agent node that last performed work\n",
    "    next: Annotation<string>({\n",
    "        reducer: (x, y) => y ?? x ?? END,\n",
    "        default: () => END,\n",
    "    }),\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"FivU0jNSyZ0V9oCixR8VRPZ11EMGcUVS\"\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.env.TAVILY_API_KEY = \"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\";\n",
    "process.env.MISTRAL_API_KEY = \"FivU0jNSyZ0V9oCixR8VRPZ11EMGcUVS\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import \"npm:tsx\"; // Only for running this in TSLab. See: https://github.com/yunabe/tslab/issues/72\n",
    "import { TavilySearchResults } from \"npm:@langchain/community/tools/tavily_search\";\n",
    "import { DynamicStructuredTool } from \"npm:@langchain/core/tools\";\n",
    "import * as d3 from \"npm:d3\";\n",
    "// ----------ATTENTION----------\n",
    "// If attempting to run this notebook locally, you must follow these instructions\n",
    "// to install the necessary system dependencies for the `canvas` package.\n",
    "// https://www.npmjs.com/package/canvas#compiling\n",
    "// -----------------------------\n",
    "// import { createCanvas } from \"canvas\";\n",
    "// import { z } from \"zod\";\n",
    "// import * as tslab from \"tslab\";\n",
    "\n",
    "const additionerTool = new DynamicStructuredTool({\n",
    "    name: \"number_additionner\",\n",
    "    description: \"Additionne deux nombres\",\n",
    "    func: (a: number, b: number) => { return a + b},\n",
    "});\n",
    "\n",
    "const tavilyTool = new TavilySearchResults();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"npm:zod\";\n",
    "import { ChatMistralAI } from \"npm:@langchain/mistralai\";\n",
    "\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"npm:@langchain/core/prompts\";\n",
    "\n",
    "const members = [\"researcher\", \"number_additionner\"] as const;\n",
    "\n",
    "const systemPrompt =\n",
    "    \"You are a supervisor tasked with managing a conversation between the\" +\n",
    "    \" following workers: {members}. Given the following user request,\" +\n",
    "    \" respond with the worker to act next. Each worker will perform a\" +\n",
    "    \" task and respond with their results and status. When finished,\" +\n",
    "    \" respond with FINISH.\";\n",
    "const options = [END, ...members];\n",
    "\n",
    "// Define the routing function\n",
    "const routingTool = {\n",
    "    name: \"route\",\n",
    "    description: \"Select the next role.\",\n",
    "    schema: z.object({\n",
    "        next: z.enum([END, ...members]),\n",
    "    }),\n",
    "}\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", systemPrompt],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "    [\n",
    "        \"human\",\n",
    "        \"Given the conversation above, who should act next?\" +\n",
    "        \" Or should we FINISH? Select one of: {options}\",\n",
    "    ],\n",
    "]);\n",
    "\n",
    "const formattedPrompt = await prompt.partial({\n",
    "    options: options.join(\", \"),\n",
    "    members: members.join(\", \"),\n",
    "});\n",
    "\n",
    "const llm = new ChatMistralAI({\n",
    "    modelName: \"mistral-large-latest\",\n",
    "    temperature: 0,\n",
    "});\n",
    "\n",
    "const supervisorChain = formattedPrompt\n",
    "    .pipe(llm.bindTools(\n",
    "        [routingTool],\n",
    "        {\n",
    "            tool_choice: \"any\",\n",
    "        },\n",
    "    ))\n",
    "    // select the first one\n",
    "    .pipe((x) => (x.tool_calls[0].args));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ next: \u001b[32m\"researcher\"\u001b[39m }"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { HumanMessage } from \"npm:@langchain/core/messages\";\n",
    "\n",
    "await supervisorChain.invoke({\n",
    "    messages: [\n",
    "        new HumanMessage({\n",
    "            content: \"write a report on birds.\",\n",
    "        }),\n",
    "    ],\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
